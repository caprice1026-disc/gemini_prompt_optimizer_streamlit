from __future__ import annotations

from typing import Any, Dict, List

import streamlit as st
from google.genai import types

from src.gemini_api import (
    call_text_model_for_prompts,
    generate_image_bytes,
    get_api_key_from_env_or_ui,
    get_client,
)
from src.models import PromptCandidate
from src.prompts import (
    build_round1_user_prompt,
    build_round2_user_prompt,
    build_round3_user_prompt,
    build_system_instruction,
    json_schema_for_final_prompt,
    json_schema_for_prompts,
)
from src.runtime import is_running_with_streamlit
from src.state import ensure_state, reset_all
from src.ui_components import render_gallery, rank_ui, truncate


def candidates_from_payload(payload: Dict[str, Any]) -> List[PromptCandidate]:
    raw = payload.get("prompts", [])
    raw_sorted = sorted(raw, key=lambda x: int(x.get("id", 0)))
    out: List[PromptCandidate] = []
    for item in raw_sorted:
        out.append(
            PromptCandidate(
                id=int(item["id"]),
                label=str(item["label"]).strip(),
                prompt=str(item["prompt"]).strip(),
            )
        )
    return out


def final_candidate_from_payload(payload: Dict[str, Any]) -> PromptCandidate:
    return PromptCandidate(
        id=int(payload["id"]),
        label=str(payload["label"]).strip(),
        prompt=str(payload["prompt"]).strip(),
    )


def render_app() -> None:
    st.set_page_config(page_title="Gemini Prompt Optimizer", layout="wide")
    ensure_state()

    st.title("ðŸ§ª ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ– (Gemini + Streamlit)")
    st.caption("9ä»¶â†’ãƒ©ãƒ³ã‚­ãƒ³ã‚° â†’ 4ä»¶â†’ãƒ©ãƒ³ã‚­ãƒ³ã‚° â†’ 1æ¡ˆï¼ˆæœ€çµ‚ï¼‰ã¨ã„ã†æµã‚Œã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµžã‚Šè¾¼ã¿ã¾ã™ã€‚ðŸƒ")

    with st.sidebar:
        st.header("è¨­å®š")
        api_key_ui = st.text_input("Gemini API Key (GEMINI_API_KEY)", type="password")
        api_key = get_api_key_from_env_or_ui(api_key_ui)

        st.markdown("---")
        st.subheader("ãƒ¢ãƒ‡ãƒ«")
        st.session_state["settings"]["text_model"] = st.selectbox(
            "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ« (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ)",
            options=["gemini-3-flash-preview", "gemini-3-pro-preview"],
            index=0 if st.session_state["settings"]["text_model"] == "gemini-3-flash-preview" else 1,
        )
        st.session_state["settings"]["image_model"] = st.selectbox(
            "ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«",
            options=["gemini-2.5-flash-image", "gemini-3-pro-image-preview"],
            index=0 if st.session_state["settings"]["image_model"] == "gemini-2.5-flash-image" else 1,
        )

        st.markdown("---")
        st.subheader("å‡ºåŠ›")
        st.session_state["settings"]["aspect_ratio"] = st.selectbox(
            "ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”",
            options=["1:1", "16:9", "9:16", "4:3", "3:4"],
            index=["1:1", "16:9", "9:16", "4:3", "3:4"].index(st.session_state["settings"]["aspect_ratio"]),
        )
        st.session_state["settings"]["prompt_language"] = st.selectbox(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨€èªž",
            options=["æ—¥æœ¬èªž", "English"],
            index=0 if st.session_state["settings"]["prompt_language"] == "æ—¥æœ¬èªž" else 1,
        )

        st.markdown("---")
        st.subheader("æ¸©åº¦ (å¤šæ§˜æ€§)")
        st.session_state["settings"]["temperature_round1"] = st.slider(
            "Round 1 (9ä»¶)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round1"]), 0.05
        )
        st.session_state["settings"]["temperature_round2"] = st.slider(
            "Round 2 (4ä»¶)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round2"]), 0.05
        )
        st.session_state["settings"]["temperature_round3"] = st.slider(
            "Round 3 (æœ€çµ‚)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round3"]), 0.05
        )

        st.markdown("---")
        st.session_state["settings"]["use_multimodal_feedback"] = st.toggle(
            "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆæ™‚ã«ç”»åƒã‚‚æ¸¡ã™ (ç²¾åº¦â†‘/ã‚³ã‚¹ãƒˆâ†‘)",
            value=bool(st.session_state["settings"]["use_multimodal_feedback"]),
            help="Round 2 / Final ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆæ™‚ã€ä¸Šä½ãƒ»ä¸‹ä½ã®ç”»åƒã‚’ Gemini ã«æ¸¡ã—ã¦æ”¹å–„ã•ã›ã¾ã™ã€‚",
        )

        st.markdown("---")
        if st.button("ðŸ§¹ å…¨ãƒªã‚»ãƒƒãƒˆ"):
            reset_all()
            st.rerun()

        st.caption(
            "APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY / GOOGLE_API_KEY ã§ã‚‚OKã€‚\n"
            "Streamlit Cloudãªã‚‰ st.secrets ã§ç®¡ç†æŽ¨å¥¨ã€‚"
        )

    st.header("â‘  ä½œã‚ŠãŸã„ç”»åƒã®ã‚¤ãƒ¡ãƒ¼ã‚¸")
    st.session_state["user_intent"] = st.text_area(
        "ã©ã‚“ãªç”»åƒã‚’ä½œã‚ŠãŸã„ã§ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šã€Žé›¨ã®å¤œã®æ±äº¬ã€ãƒã‚ªãƒ³ãŒåå°„ã™ã‚‹è·¯åœ°ã€ã‚·ãƒãƒžãƒ†ã‚£ãƒƒã‚¯ãªå†™çœŸã€ï¼‰",
        value=st.session_state["user_intent"],
        height=120,
    )

    cols = st.columns(2)
    with cols[0]:
        st.session_state["must_include"] = st.text_input(
            "å¿…ãšå…¥ã‚Œã¦ã»ã—ã„è¦ç´ ï¼ˆä»»æ„ï¼‰",
            value=st.session_state["must_include"],
        )
    with cols[1]:
        st.session_state["must_avoid"] = st.text_input(
            "é¿ã‘ãŸã„è¦ç´ ï¼ˆä»»æ„ï¼‰",
            value=st.session_state["must_avoid"],
        )

    st.session_state["extra_feedback"] = st.text_area(
        "è£œè¶³ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆä»»æ„ï¼‰ï¼šè‰²å‘³ã€é›°å›²æ°—ã€æ§‹å›³ã€ç”»é¢¨ãªã©",
        value=st.session_state["extra_feedback"],
        height=80,
    )

    if not st.session_state["user_intent"].strip():
        st.warning("ã¾ãšã€Žä½œã‚ŠãŸã„ç”»åƒã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return

    if not api_key:
        st.error("Gemini APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return

    client = get_client(api_key)

    # Round 1
    st.header("â‘¡â‘¢ Round 1 â€” 9æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ")
    r1 = st.session_state["round1"]

    col_a, col_b = st.columns([1, 1])
    with col_a:
        if st.button("ðŸš€ Round 1 ã‚’å®Ÿè¡Œ (9æ¡ˆ + ç”»åƒç”Ÿæˆ)", disabled=bool(r1["candidates"])):
            with st.spinner("Round 1: 9æ¡ˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
                sys_inst = build_system_instruction(st.session_state["settings"]["prompt_language"])
                schema = json_schema_for_prompts(9)
                user_prompt = build_round1_user_prompt(
                    st.session_state["user_intent"],
                    st.session_state["must_include"],
                    st.session_state["must_avoid"],
                    st.session_state["settings"]["prompt_language"],
                )
                payload = call_text_model_for_prompts(
                    client=client,
                    model=st.session_state["settings"]["text_model"],
                    schema=schema,
                    system_instruction=sys_inst,
                    user_prompt=user_prompt,
                    temperature=st.session_state["settings"]["temperature_round1"],
                )
                candidates = candidates_from_payload(payload)
                # Force stable ids 1..9 to avoid duplicates from the model
                for i, c in enumerate(candidates, start=1):
                    c.id = i
                r1["candidates"] = [c.__dict__ for c in candidates]
                r1["images"] = {}
                r1["errors"] = {}
                r1["ranking"] = []

            with st.spinner("Round 1: ç”»åƒã‚’ç”Ÿæˆä¸­â€¦(9æžš)"):
                prog = st.progress(0.0)
                for i, cand in enumerate(r1["candidates"]):
                    cid = str(cand["id"])
                    try:
                        img_bytes = generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r1["images"][cid] = img_bytes
                    except Exception as e:
                        r1["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(r1["candidates"])))
                prog.empty()

            st.success("Round 1 å®Œäº†ã€‚ä¸‹ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚")
            st.rerun()

    with col_b:
        if r1["candidates"] and st.button("â™»ï¸ Round 1 ç”»åƒã‚’å†ç”Ÿæˆ (å¤±æ•—åˆ†ã®ã¿)"):
            with st.spinner("å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆä¸­â€¦"):
                missing = [c for c in r1["candidates"] if str(c["id"]) not in r1["images"]]
                prog = st.progress(0.0)
                for i, cand in enumerate(missing):
                    cid = str(cand["id"])
                    try:
                        img_bytes = generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r1["images"][cid] = img_bytes
                        r1["errors"].pop(cid, None)
                    except Exception as e:
                        r1["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(missing)))
                prog.empty()
            st.rerun()

    if r1["candidates"]:
        render_gallery(r1["candidates"], r1["images"], cols=3)

        if r1["errors"]:
            st.warning("ä¸€éƒ¨ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¿…è¦ãªã‚‰ã€Žå¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                st.json(r1["errors"])

        st.header("â‘£ Round 1 â€” ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        ranking1 = rank_ui("Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°", r1["candidates"], default_ranking=r1["ranking"] or None)
        if ranking1 and st.button("âœ… Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç¢ºå®š"):
            r1["ranking"] = ranking1
            st.success("Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚æ¬¡ã« Round 2 ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
            st.rerun()

    # Round 2
    st.header("â‘¤â‘¥ Round 2 â€” 4æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ")
    r2 = st.session_state["round2"]

    if not r1["ranking"]:
        st.info("Round 2 ã«é€²ã‚€ã«ã¯ã€ã¾ãš Round 1 ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç¢ºå®šã—ã¦ãã ã•ã„ã€‚")
        return

    col_c, col_d = st.columns([1, 1])
    with col_c:
        if st.button("ðŸš€ Round 2 ã‚’å®Ÿè¡Œ (4æ¡ˆ + ç”»åƒç”Ÿæˆ)", disabled=bool(r2["candidates"])):
            with st.spinner("Round 2: 4æ¡ˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
                sys_inst = build_system_instruction(st.session_state["settings"]["prompt_language"])
                schema = json_schema_for_prompts(4)

                use_imgs = bool(st.session_state["settings"]["use_multimodal_feedback"])
                if use_imgs:
                    top_id = str(r1["ranking"][0])
                    bottom_id = str(r1["ranking"][-1])

                    contents: List[Any] = []
                    contents.append(
                        build_round2_user_prompt(
                            st.session_state["user_intent"],
                            st.session_state["must_include"],
                            st.session_state["must_avoid"],
                            st.session_state["extra_feedback"],
                            r1["candidates"],
                            r1["ranking"],
                        )
                    )
                    if top_id in r1["images"]:
                        contents.append("Best-ranked image (rank=1):")
                        contents.append(types.Part.from_bytes(data=r1["images"][top_id], mime_type="image/png"))
                    if bottom_id in r1["images"]:
                        contents.append("Worst-ranked image (last rank):")
                        contents.append(types.Part.from_bytes(data=r1["images"][bottom_id], mime_type="image/png"))

                    user_prompt_any: Any = contents
                else:
                    user_prompt_any = build_round2_user_prompt(
                        st.session_state["user_intent"],
                        st.session_state["must_include"],
                        st.session_state["must_avoid"],
                        st.session_state["extra_feedback"],
                        r1["candidates"],
                        r1["ranking"],
                    )

                payload = call_text_model_for_prompts(
                    client=client,
                    model=st.session_state["settings"]["text_model"],
                    schema=schema,
                    system_instruction=sys_inst,
                    user_prompt=user_prompt_any,
                    temperature=st.session_state["settings"]["temperature_round2"],
                )
                candidates = candidates_from_payload(payload)

                # Re-id them as 1..4 for UI clarity
                for i, c in enumerate(candidates, start=1):
                    c.id = i

                r2["candidates"] = [c.__dict__ for c in candidates]
                r2["images"] = {}
                r2["errors"] = {}
                r2["ranking"] = []

            with st.spinner("Round 2: ç”»åƒã‚’ç”Ÿæˆä¸­â€¦(4æžš)"):
                prog = st.progress(0.0)
                for i, cand in enumerate(r2["candidates"]):
                    cid = str(cand["id"])
                    try:
                        img_bytes = generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r2["images"][cid] = img_bytes
                    except Exception as e:
                        r2["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(r2["candidates"])))
                prog.empty()

            st.success("Round 2 å®Œäº†ã€‚ä¸‹ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚")
            st.rerun()

    with col_d:
        if r2["candidates"] and st.button("â™»ï¸ Round 2 ç”»åƒã‚’å†ç”Ÿæˆ (å¤±æ•—åˆ†ã®ã¿)"):
            with st.spinner("å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆä¸­â€¦"):
                missing = [c for c in r2["candidates"] if str(c["id"]) not in r2["images"]]
                prog = st.progress(0.0)
                for i, cand in enumerate(missing):
                    cid = str(cand["id"])
                    try:
                        img_bytes = generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r2["images"][cid] = img_bytes
                        r2["errors"].pop(cid, None)
                    except Exception as e:
                        r2["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(missing)))
                prog.empty()
            st.rerun()

    if r2["candidates"]:
        render_gallery(r2["candidates"], r2["images"], cols=2)

        if r2["errors"]:
            st.warning("ä¸€éƒ¨ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¿…è¦ãªã‚‰ã€Žå¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                st.json(r2["errors"])

        st.header("â‘¦ Round 2 â€” ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        ranking2 = rank_ui("Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°", r2["candidates"], default_ranking=r2["ranking"] or None)
        if ranking2 and st.button("âœ… Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç¢ºå®š"):
            r2["ranking"] = ranking2
            st.success("Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚æ¬¡ã«æœ€çµ‚ç”Ÿæˆã¸é€²ã‚ã¾ã™ã€‚")
            st.rerun()

    # Final
    st.header("â‘§â‘¨ Final â€” 1æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ â†’ è¡¨ç¤º")

    if not r2["ranking"]:
        st.info("æœ€çµ‚ç”Ÿæˆã«é€²ã‚€ã«ã¯ã€Round 2 ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç¢ºå®šã—ã¦ãã ã•ã„ã€‚")
        return

    if st.button("ðŸ æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ç”»åƒã‚’ç”Ÿæˆ", disabled=bool(st.session_state["final"]["candidate"])):
        with st.spinner("æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
            sys_inst = build_system_instruction(st.session_state["settings"]["prompt_language"])
            schema = json_schema_for_final_prompt()

            use_imgs = bool(st.session_state["settings"]["use_multimodal_feedback"])
            if use_imgs:
                top_id = str(r2["ranking"][0])
                bottom_id = str(r2["ranking"][-1])
                contents: List[Any] = []
                contents.append(
                    build_round3_user_prompt(
                        st.session_state["user_intent"],
                        st.session_state["must_include"],
                        st.session_state["must_avoid"],
                        st.session_state["extra_feedback"],
                        r2["candidates"],
                        r2["ranking"],
                    )
                )
                if top_id in r2["images"]:
                    contents.append("Best-ranked image (rank=1):")
                    contents.append(types.Part.from_bytes(data=r2["images"][top_id], mime_type="image/png"))
                if bottom_id in r2["images"]:
                    contents.append("Worst-ranked image (last rank):")
                    contents.append(types.Part.from_bytes(data=r2["images"][bottom_id], mime_type="image/png"))
                user_prompt_any: Any = contents
            else:
                user_prompt_any = build_round3_user_prompt(
                    st.session_state["user_intent"],
                    st.session_state["must_include"],
                    st.session_state["must_avoid"],
                    st.session_state["extra_feedback"],
                    r2["candidates"],
                    r2["ranking"],
                )

            payload = call_text_model_for_prompts(
                client=client,
                model=st.session_state["settings"]["text_model"],
                schema=schema,
                system_instruction=sys_inst,
                user_prompt=user_prompt_any,
                temperature=st.session_state["settings"]["temperature_round3"],
            )
            final_cand = final_candidate_from_payload(payload)
            final_cand.id = 1
            st.session_state["final"]["candidate"] = final_cand.__dict__
            st.session_state["final"]["image"] = None
            st.session_state["final"]["error"] = None

        with st.spinner("æœ€çµ‚ç”»åƒã‚’ç”Ÿæˆä¸­â€¦"):
            try:
                img_bytes = generate_image_bytes(
                    client=client,
                    model=st.session_state["settings"]["image_model"],
                    prompt=st.session_state["final"]["candidate"]["prompt"],
                    aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                )
                st.session_state["final"]["image"] = img_bytes
            except Exception as e:
                st.session_state["final"]["error"] = str(e)

        st.rerun()

    final = st.session_state["final"]
    if final["candidate"]:
        st.subheader("æœ€çµ‚çµæžœ")
        st.markdown(f"### âœ… {truncate(final['candidate']['label'], 80)}")
        if final["image"]:
            st.image(final["image"], use_container_width=True)
        else:
            st.error("ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            if final["error"]:
                st.code(final["error"])

        st.markdown("#### æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        st.code(final["candidate"]["prompt"], language="text")

        st.download_button(
            "ðŸ“¥ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.txt)",
            data=final["candidate"]["prompt"].encode("utf-8"),
            file_name="final_prompt.txt",
            mime="text/plain",
        )
        if final["image"]:
            st.download_button(
                "ðŸ“¥ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.png)",
                data=final["image"],
                file_name="final_image.png",
                mime="image/png",
            )


def main() -> None:
    if not is_running_with_streamlit():
        print("This app must be run with: streamlit run app.py")
        return
    render_app()


if __name__ == "__main__":
    main()
