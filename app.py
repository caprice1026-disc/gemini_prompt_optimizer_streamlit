import io
import json
import os
import textwrap
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

import streamlit as st
from PIL import Image

# Gemini SDK
from google import genai
from google.genai import types

# Optional: drag & drop ranking
try:
    from streamlit_sortables import sort_items  # pip install streamlit-sortables
    _HAS_SORTABLES = True
except Exception:
    _HAS_SORTABLES = False


# -----------------------------
# Data models (lightweight)
# -----------------------------
@dataclass
class PromptCandidate:
    id: int
    label: str
    prompt: str


# -----------------------------
# Utilities
# -----------------------------
def _truncate(s: str, n: int = 60) -> str:
    s = (s or "").strip().replace("\n", " ")
    return s if len(s) <= n else s[: n - 1] + "â€¦"


def _ensure_state() -> None:
    """Initialize session_state keys."""
    defaults = {
        "user_intent": "",
        "must_include": "",
        "must_avoid": "",
        "extra_feedback": "",
        "settings": {
            "text_model": "gemini-3-flash-preview",
            "image_model": "gemini-2.5-flash-image",
            "aspect_ratio": "1:1",
            "prompt_language": "æ—¥æœ¬èª",
            "temperature_round1": 0.9,
            "temperature_round2": 0.7,
            "temperature_round3": 0.5,
            "use_multimodal_feedback": False,
        },
        "round1": {
            "candidates": [],  # List[PromptCandidate as dict]
            "images": {},      # id -> bytes (png)
            "errors": {},      # id -> str
            "ranking": [],     # List[int]
        },
        "round2": {
            "candidates": [],
            "images": {},
            "errors": {},
            "ranking": [],
        },
        "final": {
            "candidate": None,  # PromptCandidate as dict
            "image": None,      # bytes
            "error": None,      # str
        },
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


def _reset_all() -> None:
    for k in ["round1", "round2", "final"]:
        if k in st.session_state:
            del st.session_state[k]
    _ensure_state()


def _get_api_key_from_env_or_ui(ui_key: str) -> Optional[str]:
    if ui_key and ui_key.strip():
        return ui_key.strip()
    return os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")


@st.cache_resource(show_spinner=False)
def _get_client(api_key: str) -> genai.Client:
    # Gemini Developer API (Google AI Studio key)
    return genai.Client(api_key=api_key)


def _json_schema_for_prompts(n: int) -> Dict[str, Any]:
    # Standard JSON Schema subset supported by Gemini structured output mode.
    return {
        "type": "object",
        "properties": {
            "prompts": {
                "type": "array",
                "minItems": n,
                "maxItems": n,
                "items": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer", "minimum": 1},
                        "label": {"type": "string", "minLength": 1},
                        "prompt": {"type": "string", "minLength": 1},
                    },
                    "required": ["id", "label", "prompt"],
                    "additionalProperties": False,
                },
            }
        },
        "required": ["prompts"],
        "additionalProperties": False,
    }


def _json_schema_for_final_prompt() -> Dict[str, Any]:
    return {
        "type": "object",
        "properties": {
            "id": {"type": "integer", "minimum": 1},
            "label": {"type": "string", "minLength": 1},
            "prompt": {"type": "string", "minLength": 1},
        },
        "required": ["id", "label", "prompt"],
        "additionalProperties": False,
    }


def _build_system_instruction(language: str) -> str:
    lang_hint = "æ—¥æœ¬èª" if language == "æ—¥æœ¬èª" else "English"
    return textwrap.dedent(
        f'''
        You are a senior prompt engineer for image generation.
        Produce high-quality prompts that work well for Gemini 2.5 Flash Image (Nano Banana).
        Write prompts in {lang_hint}.
        Each prompt must be self-contained and describe:
        - subject, environment, composition, lighting, style/medium
        - optionally camera details (lens, angle) when relevant
        - clear constraints and what to avoid (no watermarks, no unreadable text, etc.) when useful
        Avoid referencing copyrighted characters, trademarks, living artists, or brand names unless the user explicitly requests it.
        Do NOT output markdown. Only output valid JSON that matches the provided schema.
        '''
    ).strip()


def _call_text_model_for_prompts(
    client: genai.Client,
    model: str,
    schema: Dict[str, Any],
    system_instruction: str,
    user_prompt: Any,
    temperature: float,
) -> Dict[str, Any]:
    config = {
        "response_mime_type": "application/json",
        "response_json_schema": schema,
        "system_instruction": system_instruction,
        "temperature": float(temperature),
        "max_output_tokens": 4096,
    }
    resp = client.models.generate_content(model=model, contents=user_prompt, config=config)

    # Prefer native parsed object (SDK convenience)
    if getattr(resp, "parsed", None) is not None:
        return resp.parsed  # type: ignore[return-value]

    # Fallback: parse text manually
    try:
        return json.loads(resp.text)
    except Exception as e:
        raise ValueError(f"JSON parse failed. Raw text: {resp.text[:500]}") from e


def _candidates_from_payload(payload: Dict[str, Any]) -> List[PromptCandidate]:
    raw = payload.get("prompts", [])
    raw_sorted = sorted(raw, key=lambda x: int(x.get("id", 0)))
    out: List[PromptCandidate] = []
    for item in raw_sorted:
        out.append(
            PromptCandidate(
                id=int(item["id"]),
                label=str(item["label"]).strip(),
                prompt=str(item["prompt"]).strip(),
            )
        )
    return out


def _final_candidate_from_payload(payload: Dict[str, Any]) -> PromptCandidate:
    return PromptCandidate(
        id=int(payload["id"]),
        label=str(payload["label"]).strip(),
        prompt=str(payload["prompt"]).strip(),
    )


def _generate_image_bytes(
    client: genai.Client,
    model: str,
    prompt: str,
    aspect_ratio: str,
) -> bytes:
    """Generate a single PNG image as bytes using Gemini image model."""
    resp = client.models.generate_content(
        model=model,
        contents=prompt,
        config=types.GenerateContentConfig(
            response_modalities=["IMAGE"],
            image_config=types.ImageConfig(aspect_ratio=aspect_ratio),
        ),
    )

    for part in resp.parts:
        if getattr(part, "inline_data", None):
            img: Image.Image = part.as_image()
            buf = io.BytesIO()
            img.save(buf, format="PNG")
            return buf.getvalue()

    raise RuntimeError("Model response did not include an image.")


def _render_gallery(candidates: List[Dict[str, Any]], images: Dict[str, bytes], cols: int = 3) -> None:
    if not candidates:
        return
    cols = max(1, min(cols, 5))
    rows = (len(candidates) + cols - 1) // cols

    idx = 0
    for _ in range(rows):
        cs = st.columns(cols)
        for c in cs:
            if idx >= len(candidates):
                break
            cand = candidates[idx]
            cid = str(cand["id"])
            with c:
                st.markdown(f"### #{cid} â€” {_truncate(cand['label'], 40)}")
                if cid in images:
                    st.image(images[cid], use_container_width=True)
                else:
                    st.info("ã¾ã ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¦‹ã‚‹"):
                    st.code(cand["prompt"], language="text")
            idx += 1


def _rank_ui(
    title: str,
    candidates: List[Dict[str, Any]],
    default_ranking: Optional[List[int]] = None,
) -> Optional[List[int]]:
    if not candidates:
        return None

    st.subheader(title)
    st.caption("ä¸Šã»ã©ã€æƒ³åƒã«è¿‘ã„(=è‰¯ã„)ã€ã§ã™ã€‚")

    ids = [int(c["id"]) for c in candidates]
    labels = {int(c["id"]): c["label"] for c in candidates}

    methods = ["é †ä½ã‚’æ•°å­—ã§å…¥åŠ›"]
    if _HAS_SORTABLES:
        methods.insert(0, "ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ— (ãŠã™ã™ã‚)")

    method = st.radio("ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ–¹æ³•", methods, horizontal=True, key=f"rank_method_{title}")

    if method.startswith("ãƒ‰ãƒ©ãƒƒã‚°") and _HAS_SORTABLES:
        items: List[str] = []
        if default_ranking and len(default_ranking) == len(ids):
            for i in default_ranking:
                items.append(f"{i}: {_truncate(labels[i], 60)}")
        else:
            for i in ids:
                items.append(f"{i}: {_truncate(labels[i], 60)}")

        custom_style = '''
        .sortable-container { counter-reset: item; }
        .sortable-item::before { content: counter(item) ". "; counter-increment: item; }
        '''
        sorted_items = sort_items(items, custom_style=custom_style)
        ranking = [int(x.split(":", 1)[0].strip()) for x in sorted_items]
        st.write("ç¾åœ¨ã®é †ç•ª:", ranking)
        return ranking

    import pandas as pd

    if default_ranking and len(default_ranking) == len(ids):
        initial_rank = {cid: i + 1 for i, cid in enumerate(default_ranking)}
    else:
        initial_rank = {cid: i + 1 for i, cid in enumerate(ids)}

    df = pd.DataFrame(
        [{"id": cid, "label": _truncate(labels[cid], 80), "rank(1=best)": initial_rank[cid]} for cid in ids]
    )
    edited = st.data_editor(
        df,
        hide_index=True,
        use_container_width=True,
        column_config={
            "id": st.column_config.NumberColumn(disabled=True),
            "label": st.column_config.TextColumn(disabled=True),
            "rank(1=best)": st.column_config.NumberColumn(min_value=1, max_value=len(ids), step=1),
        },
        key=f"rank_editor_{title}",
    )

    ranks = list(edited["rank(1=best)"])
    if len(set(ranks)) != len(ranks):
        st.warning("rank ãŒé‡è¤‡ã—ã¦ã„ã¾ã™ã€‚1ã€œN ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã—ã¦ãã ã•ã„ã€‚")
        return None
    if any((r < 1 or r > len(ids)) for r in ranks):
        st.warning("rank ã®ç¯„å›²ãŒä¸æ­£ã§ã™ã€‚")
        return None

    edited_sorted = edited.sort_values("rank(1=best)")
    ranking = [int(x) for x in edited_sorted["id"].tolist()]
    st.write("ç¾åœ¨ã®é †ç•ª:", ranking)
    return ranking


def _build_round1_user_prompt(user_intent: str, must_include: str, must_avoid: str, language: str) -> str:
    return textwrap.dedent(
        f'''
        The user wants prompts for image generation.

        User intent:
        {user_intent.strip()}

        Must include (if any):
        {must_include.strip() or "None"}

        Must avoid (if any):
        {must_avoid.strip() or "None"}

        Task:
        Create 9 distinct image-generation prompts exploring different directions (composition, style, lighting, perspective)
        while staying faithful to the user intent.

        Constraints:
        - Keep each prompt concise (1-3 sentences), but concrete.
        - Prefer scene descriptions over keyword salad.
        - If you include â€œavoid/negativeâ€ instructions, embed them naturally at the end.
        - Do not mention any model names.
        - Output strictly JSON matching the schema.
        '''
    ).strip()


def _build_round2_user_prompt(
    user_intent: str,
    must_include: str,
    must_avoid: str,
    extra_feedback: str,
    round1_candidates: List[Dict[str, Any]],
    round1_ranking: List[int],
) -> str:
    lines = []
    for c in round1_candidates:
        cid = int(c["id"])
        rank = round1_ranking.index(cid) + 1 if cid in round1_ranking else None
        lines.append(f"- id={cid}, rank={rank}, label={c['label']}\n  prompt={c['prompt']}")
    blob = "\n".join(lines)

    return textwrap.dedent(
        f'''
        We are iteratively optimizing an image generation prompt.

        User intent:
        {user_intent.strip()}

        Must include (if any):
        {must_include.strip() or "None"}

        Must avoid (if any):
        {must_avoid.strip() or "None"}

        Additional user feedback (optional):
        {extra_feedback.strip() or "None"}

        Round 1 results:
        The user ranked the candidates from best (rank=1) to worst.

        Candidates:
        {blob}

        Task:
        Create 4 new prompts that move closer to what the user prefers.
        - Preserve the strongest qualities of the top-ranked prompts.
        - Avoid traits likely responsible for the bottom-ranked prompts being worse.
        - Keep prompts diverse but clearly improved vs round 1.
        - Output strictly JSON matching the schema.
        '''
    ).strip()


def _build_round3_user_prompt(
    user_intent: str,
    must_include: str,
    must_avoid: str,
    extra_feedback: str,
    round2_candidates: List[Dict[str, Any]],
    round2_ranking: List[int],
) -> str:
    lines = []
    for c in round2_candidates:
        cid = int(c["id"])
        rank = round2_ranking.index(cid) + 1 if cid in round2_ranking else None
        lines.append(f"- id={cid}, rank={rank}, label={c['label']}\n  prompt={c['prompt']}")
    blob = "\n".join(lines)

    return textwrap.dedent(
        f'''
        We are finishing an iterative prompt optimization process.

        User intent:
        {user_intent.strip()}

        Must include (if any):
        {must_include.strip() or "None"}

        Must avoid (if any):
        {must_avoid.strip() or "None"}

        Additional user feedback (optional):
        {extra_feedback.strip() or "None"}

        Round 2 results:
        The user ranked 4 candidates from best (rank=1) to worst.

        Candidates:
        {blob}

        Task:
        Produce ONE final best prompt that most likely matches the user's preference.
        - Make it specific and unambiguous.
        - Keep it concise (1-3 sentences).
        - If useful, include a short â€œavoidâ€ clause at the end.
        - Output strictly JSON matching the schema.
        '''
    ).strip()


def main() -> None:
    st.set_page_config(page_title="Gemini Prompt Optimizer", layout="wide")
    _ensure_state()

    st.title("ğŸ§ª ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ– (Gemini + Streamlit)")
    st.caption("9æ¡ˆ â†’ ãƒ©ãƒ³ã‚­ãƒ³ã‚° â†’ 4æ¡ˆ â†’ ãƒ©ãƒ³ã‚­ãƒ³ã‚° â†’ 1æ¡ˆï¼ˆæœ€çµ‚ï¼‰ ã¨ã„ã†æµã‚Œã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµã‚Šè¾¼ã¿ã¾ã™ã€‚ğŸŒ")

    with st.sidebar:
        st.header("è¨­å®š")
        api_key_ui = st.text_input("Gemini API Key (GEMINI_API_KEY)", type="password")
        api_key = _get_api_key_from_env_or_ui(api_key_ui)

        st.markdown("---")
        st.subheader("ãƒ¢ãƒ‡ãƒ«")
        st.session_state["settings"]["text_model"] = st.selectbox(
            "ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ« (ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ)",
            options=["gemini-3-flash-preview", "gemini-3-pro-preview"],
            index=0 if st.session_state["settings"]["text_model"] == "gemini-3-flash-preview" else 1,
        )
        st.session_state["settings"]["image_model"] = st.selectbox(
            "ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«",
            options=["gemini-2.5-flash-image", "gemini-3-pro-image-preview"],
            index=0 if st.session_state["settings"]["image_model"] == "gemini-2.5-flash-image" else 1,
        )

        st.markdown("---")
        st.subheader("å‡ºåŠ›")
        st.session_state["settings"]["aspect_ratio"] = st.selectbox(
            "ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”",
            options=["1:1", "16:9", "9:16", "4:3", "3:4"],
            index=["1:1", "16:9", "9:16", "4:3", "3:4"].index(st.session_state["settings"]["aspect_ratio"]),
        )
        st.session_state["settings"]["prompt_language"] = st.selectbox(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨€èª",
            options=["æ—¥æœ¬èª", "English"],
            index=0 if st.session_state["settings"]["prompt_language"] == "æ—¥æœ¬èª" else 1,
        )

        st.markdown("---")
        st.subheader("æ¸©åº¦ (å¤šæ§˜æ€§)")
        st.session_state["settings"]["temperature_round1"] = st.slider("Round 1 (9æ¡ˆ)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round1"]), 0.05)
        st.session_state["settings"]["temperature_round2"] = st.slider("Round 2 (4æ¡ˆ)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round2"]), 0.05)
        st.session_state["settings"]["temperature_round3"] = st.slider("Round 3 (æœ€çµ‚)", 0.0, 1.5, float(st.session_state["settings"]["temperature_round3"]), 0.05)

        st.markdown("---")
        st.session_state["settings"]["use_multimodal_feedback"] = st.toggle(
            "ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”Ÿæˆæ™‚ã«ç”»åƒã‚‚æ¸¡ã™ (ç²¾åº¦â†‘/ã‚³ã‚¹ãƒˆâ†‘)",
            value=bool(st.session_state["settings"]["use_multimodal_feedback"]),
            help="Round 2 / Final ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆæ™‚ã€ä¸Šä½/ä¸‹ä½ã®ç”»åƒã‚’ Gemini 3 ã«æ¸¡ã—ã¦åˆ†æã•ã›ã¾ã™ã€‚",
        )

        st.markdown("---")
        if st.button("ğŸ§¹ å…¨ãƒªã‚»ãƒƒãƒˆ"):
            _reset_all()
            st.rerun()

        st.caption(
            "APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY / GOOGLE_API_KEY ã§ã‚‚OKã€‚\n"
            "Streamlit Cloudãªã‚‰ st.secrets ã§ç®¡ç†æ¨å¥¨ã€‚"
        )

    st.header("â‘  ä½œã‚ŠãŸã„ç”»åƒã®ã‚¤ãƒ¡ãƒ¼ã‚¸")
    st.session_state["user_intent"] = st.text_area(
        "ã©ã‚“ãªç”»åƒã‚’ä½œã‚ŠãŸã„ï¼Ÿï¼ˆä¾‹ï¼šã€é›¨ã®å¤œã®æ±äº¬ã€ãƒã‚ªãƒ³ãŒåå°„ã™ã‚‹è·¯åœ°ã€ã‚·ãƒãƒãƒ†ã‚£ãƒƒã‚¯ãªå†™çœŸã€ï¼‰",
        value=st.session_state["user_intent"],
        height=120,
    )

    cols = st.columns(2)
    with cols[0]:
        st.session_state["must_include"] = st.text_input("å¿…ãšå…¥ã‚Œã¦æ¬²ã—ã„è¦ç´ ï¼ˆä»»æ„ï¼‰", value=st.session_state["must_include"])
    with cols[1]:
        st.session_state["must_avoid"] = st.text_input("é¿ã‘ãŸã„è¦ç´ ï¼ˆä»»æ„ï¼‰", value=st.session_state["must_avoid"])

    st.session_state["extra_feedback"] = st.text_area(
        "è£œè¶³ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆä»»æ„ï¼šè‰²å‘³ã€é›°å›²æ°—ã€æ§‹å›³ã€ç”»é¢¨ãªã©ï¼‰",
        value=st.session_state["extra_feedback"],
        height=80,
    )

    if not st.session_state["user_intent"].strip():
        st.warning("ã¾ãšã¯ã€ä½œã‚ŠãŸã„ç”»åƒã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        return

    if not api_key:
        st.error("Gemini APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¥åŠ›ã™ã‚‹ã‹ã€ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return

    client = _get_client(api_key)

    # Round 1
    st.header("â‘¡â‘¢ Round 1 â€” 9æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ")
    r1 = st.session_state["round1"]

    colA, colB = st.columns([1, 1])
    with colA:
        if st.button("ğŸš€ Round 1 ã‚’å®Ÿè¡Œ (9æ¡ˆ + ç”»åƒ9æš)", disabled=bool(r1["candidates"])):
            with st.spinner("Round 1: 9æ¡ˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
                sys_inst = _build_system_instruction(st.session_state["settings"]["prompt_language"])
                schema = _json_schema_for_prompts(9)
                user_prompt = _build_round1_user_prompt(
                    st.session_state["user_intent"],
                    st.session_state["must_include"],
                    st.session_state["must_avoid"],
                    st.session_state["settings"]["prompt_language"],
                )
                payload = _call_text_model_for_prompts(
                    client=client,
                    model=st.session_state["settings"]["text_model"],
                    schema=schema,
                    system_instruction=sys_inst,
                    user_prompt=user_prompt,
                    temperature=st.session_state["settings"]["temperature_round1"],
                )
                candidates = _candidates_from_payload(payload)
                # Force stable ids 1..9 to avoid duplicates from the model
                for i, c in enumerate(candidates, start=1):
                    c.id = i
                r1["candidates"] = [c.__dict__ for c in candidates]
                r1["images"] = {}
                r1["errors"] = {}
                r1["ranking"] = []

            with st.spinner("Round 1: ç”»åƒã‚’ç”Ÿæˆä¸­â€¦ï¼ˆ9æšï¼‰"):
                prog = st.progress(0.0)
                for i, cand in enumerate(r1["candidates"]):
                    cid = str(cand["id"])
                    try:
                        img_bytes = _generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r1["images"][cid] = img_bytes
                    except Exception as e:
                        r1["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(r1["candidates"])))
                prog.empty()

            st.success("Round 1 å®Œäº†ã€‚ä¸‹ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚")
            st.rerun()

    with colB:
        if r1["candidates"] and st.button("â™»ï¸ Round 1 ç”»åƒã‚’å†ç”Ÿæˆ (å¤±æ•—åˆ†ã®ã¿)"):
            with st.spinner("å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆä¸­â€¦"):
                missing = [c for c in r1["candidates"] if str(c["id"]) not in r1["images"]]
                prog = st.progress(0.0)
                for i, cand in enumerate(missing):
                    cid = str(cand["id"])
                    try:
                        img_bytes = _generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r1["images"][cid] = img_bytes
                        r1["errors"].pop(cid, None)
                    except Exception as e:
                        r1["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(missing)))
                prog.empty()
            st.rerun()

    if r1["candidates"]:
        _render_gallery(r1["candidates"], r1["images"], cols=3)

        if r1["errors"]:
            st.warning("ä¸€éƒ¨ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¿…è¦ãªã‚‰ã€å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                st.json(r1["errors"])

        st.header("â‘£ Round 1 â€” ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        ranking1 = _rank_ui("Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°", r1["candidates"], default_ranking=r1["ranking"] if r1["ranking"] else None)
        if ranking1 and st.button("âœ… Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç¢ºå®š"):
            r1["ranking"] = ranking1
            st.success("Round 1 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚æ¬¡ã« Round 2 ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚")
            st.rerun()

    # Round 2
    st.header("â‘¤â‘¢ Round 2 â€” 4æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ")
    r2 = st.session_state["round2"]

    if not r1["ranking"]:
        st.info("Round 2 ã«é€²ã‚€ã«ã¯ã€ã¾ãš Round 1 ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç¢ºå®šã—ã¦ãã ã•ã„ã€‚")
        return

    colC, colD = st.columns([1, 1])
    with colC:
        if st.button("ğŸš€ Round 2 ã‚’å®Ÿè¡Œ (4æ¡ˆ + ç”»åƒ4æš)", disabled=bool(r2["candidates"])):
            with st.spinner("Round 2: 4æ¡ˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
                sys_inst = _build_system_instruction(st.session_state["settings"]["prompt_language"])
                schema = _json_schema_for_prompts(4)

                use_imgs = bool(st.session_state["settings"]["use_multimodal_feedback"])
                if use_imgs:
                    top_id = str(r1["ranking"][0])
                    bottom_id = str(r1["ranking"][-1])

                    contents: List[Any] = []
                    contents.append(
                        _build_round2_user_prompt(
                            st.session_state["user_intent"],
                            st.session_state["must_include"],
                            st.session_state["must_avoid"],
                            st.session_state["extra_feedback"],
                            r1["candidates"],
                            r1["ranking"],
                        )
                    )
                    if top_id in r1["images"]:
                        contents.append("Best-ranked image (rank=1):")
                        contents.append(types.Part.from_bytes(data=r1["images"][top_id], mime_type="image/png"))
                    if bottom_id in r1["images"]:
                        contents.append("Worst-ranked image (last rank):")
                        contents.append(types.Part.from_bytes(data=r1["images"][bottom_id], mime_type="image/png"))

                    user_prompt_any: Any = contents
                else:
                    user_prompt_any = _build_round2_user_prompt(
                        st.session_state["user_intent"],
                        st.session_state["must_include"],
                        st.session_state["must_avoid"],
                        st.session_state["extra_feedback"],
                        r1["candidates"],
                        r1["ranking"],
                    )

                payload = _call_text_model_for_prompts(
                    client=client,
                    model=st.session_state["settings"]["text_model"],
                    schema=schema,
                    system_instruction=sys_inst,
                    user_prompt=user_prompt_any,
                    temperature=st.session_state["settings"]["temperature_round2"],
                )
                candidates = _candidates_from_payload(payload)

                # Re-id them as 1..4 for UI clarity
                for i, c in enumerate(candidates, start=1):
                    c.id = i

                r2["candidates"] = [c.__dict__ for c in candidates]
                r2["images"] = {}
                r2["errors"] = {}
                r2["ranking"] = []

            with st.spinner("Round 2: ç”»åƒã‚’ç”Ÿæˆä¸­â€¦ï¼ˆ4æšï¼‰"):
                prog = st.progress(0.0)
                for i, cand in enumerate(r2["candidates"]):
                    cid = str(cand["id"])
                    try:
                        img_bytes = _generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r2["images"][cid] = img_bytes
                    except Exception as e:
                        r2["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(r2["candidates"])))
                prog.empty()

            st.success("Round 2 å®Œäº†ã€‚ä¸‹ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¦ãã ã•ã„ã€‚")
            st.rerun()

    with colD:
        if r2["candidates"] and st.button("â™»ï¸ Round 2 ç”»åƒã‚’å†ç”Ÿæˆ (å¤±æ•—åˆ†ã®ã¿)"):
            with st.spinner("å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆä¸­â€¦"):
                missing = [c for c in r2["candidates"] if str(c["id"]) not in r2["images"]]
                prog = st.progress(0.0)
                for i, cand in enumerate(missing):
                    cid = str(cand["id"])
                    try:
                        img_bytes = _generate_image_bytes(
                            client=client,
                            model=st.session_state["settings"]["image_model"],
                            prompt=cand["prompt"],
                            aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                        )
                        r2["images"][cid] = img_bytes
                        r2["errors"].pop(cid, None)
                    except Exception as e:
                        r2["errors"][cid] = str(e)
                    prog.progress((i + 1) / max(1, len(missing)))
                prog.empty()
            st.rerun()

    if r2["candidates"]:
        _render_gallery(r2["candidates"], r2["images"], cols=2)

        if r2["errors"]:
            st.warning("ä¸€éƒ¨ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å¿…è¦ãªã‚‰ã€å¤±æ•—åˆ†ã®ã¿å†ç”Ÿæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            with st.expander("ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                st.json(r2["errors"])

        st.header("â‘¥ Round 2 â€” ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        ranking2 = _rank_ui("Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°", r2["candidates"], default_ranking=r2["ranking"] if r2["ranking"] else None)
        if ranking2 and st.button("âœ… Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç¢ºå®š"):
            r2["ranking"] = ranking2
            st.success("Round 2 ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚æ¬¡ã«æœ€çµ‚ç”Ÿæˆã¸é€²ã‚ã¾ã™ã€‚")
            st.rerun()

    # Final
    st.header("â‘¦â‘§ Final â€” 1æ¡ˆç”Ÿæˆ â†’ ç”»åƒç”Ÿæˆ â†’ è¡¨ç¤º")

    if not r2["ranking"]:
        st.info("æœ€çµ‚ç”Ÿæˆã«é€²ã‚€ã«ã¯ã€Round 2 ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç¢ºå®šã—ã¦ãã ã•ã„ã€‚")
        return

    if st.button("ğŸ æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ + ç”»åƒã‚’ç”Ÿæˆ", disabled=bool(st.session_state["final"]["candidate"])):
        with st.spinner("æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­â€¦"):
            sys_inst = _build_system_instruction(st.session_state["settings"]["prompt_language"])
            schema = _json_schema_for_final_prompt()

            use_imgs = bool(st.session_state["settings"]["use_multimodal_feedback"])
            if use_imgs:
                top_id = str(r2["ranking"][0])
                bottom_id = str(r2["ranking"][-1])
                contents: List[Any] = []
                contents.append(
                    _build_round3_user_prompt(
                        st.session_state["user_intent"],
                        st.session_state["must_include"],
                        st.session_state["must_avoid"],
                        st.session_state["extra_feedback"],
                        r2["candidates"],
                        r2["ranking"],
                    )
                )
                if top_id in r2["images"]:
                    contents.append("Best-ranked image (rank=1):")
                    contents.append(types.Part.from_bytes(data=r2["images"][top_id], mime_type="image/png"))
                if bottom_id in r2["images"]:
                    contents.append("Worst-ranked image (last rank):")
                    contents.append(types.Part.from_bytes(data=r2["images"][bottom_id], mime_type="image/png"))
                user_prompt_any: Any = contents
            else:
                user_prompt_any = _build_round3_user_prompt(
                    st.session_state["user_intent"],
                    st.session_state["must_include"],
                    st.session_state["must_avoid"],
                    st.session_state["extra_feedback"],
                    r2["candidates"],
                    r2["ranking"],
                )

            payload = _call_text_model_for_prompts(
                client=client,
                model=st.session_state["settings"]["text_model"],
                schema=schema,
                system_instruction=sys_inst,
                user_prompt=user_prompt_any,
                temperature=st.session_state["settings"]["temperature_round3"],
            )
            final_cand = _final_candidate_from_payload(payload)
            final_cand.id = 1
            st.session_state["final"]["candidate"] = final_cand.__dict__
            st.session_state["final"]["image"] = None
            st.session_state["final"]["error"] = None

        with st.spinner("æœ€çµ‚ç”»åƒã‚’ç”Ÿæˆä¸­â€¦"):
            try:
                img_bytes = _generate_image_bytes(
                    client=client,
                    model=st.session_state["settings"]["image_model"],
                    prompt=st.session_state["final"]["candidate"]["prompt"],
                    aspect_ratio=st.session_state["settings"]["aspect_ratio"],
                )
                st.session_state["final"]["image"] = img_bytes
            except Exception as e:
                st.session_state["final"]["error"] = str(e)

        st.rerun()

    final = st.session_state["final"]
    if final["candidate"]:
        st.subheader("æœ€çµ‚çµæœ")
        st.markdown(f"### âœ… {_truncate(final['candidate']['label'], 80)}")
        if final["image"]:
            st.image(final["image"], use_container_width=True)
        else:
            st.error("ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            if final["error"]:
                st.code(final["error"])

        st.markdown("#### æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
        st.code(final["candidate"]["prompt"], language="text")

        st.download_button(
            "ğŸ“¥ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.txt)",
            data=final["candidate"]["prompt"].encode("utf-8"),
            file_name="final_prompt.txt",
            mime="text/plain",
        )
        if final["image"]:
            st.download_button(
                "ğŸ“¥ ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.png)",
                data=final["image"],
                file_name="final_image.png",
                mime="image/png",
            )


if __name__ == "__main__":
    main()
